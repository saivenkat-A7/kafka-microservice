# Event-Driven Microservice with Apache Kafka

A production-ready microservice implementation demonstrating event-driven architecture using Apache Kafka. This service acts as both a producer and consumer, publishing and processing user activity events with built-in idempotency and robust error handling.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Quick Start](#quick-start)
- [API Documentation](#api-documentation)
- [Testing](#testing)
- [Project Structure](#project-structure)
- [Configuration](#configuration)
- [Development](#development)

## âœ¨ Features

- **Event-Driven Architecture**: Asynchronous communication using Apache Kafka
- **Producer & Consumer**: Single service handles both publishing and consuming events
- **Idempotency**: Ensures events are processed exactly once using eventId
- **In-Memory Storage**: Simple event store for processed events
- **Robust Error Handling**: Graceful handling of Kafka failures and malformed messages
- **Health Checks**: Container health monitoring for all services
- **Comprehensive Testing**: Unit and integration tests with high coverage
- **Docker Support**: Fully containerized with Docker Compose
- **Graceful Shutdown**: Proper cleanup of Kafka connections

## ğŸ—ï¸ Architecture

The microservice follows a clean architecture with clear separation of concerns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Express API Layer                      â”‚
â”‚  (POST /events/generate, GET /events/processed)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                           â”‚
                 â–¼                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Kafka Producerâ”‚          â”‚Event Store   â”‚
         â”‚   Service     â”‚          â”‚(In-Memory)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                         â”‚
                 â–¼                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
         â”‚      Apache Kafka Broker       â”‚â”‚
         â”‚   (user-activity-events)       â”‚â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                  â”‚                        â”‚
                  â–¼                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
         â”‚ Kafka Consumer â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚    Service     â”‚  (Idempotent Processing)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Event Flow

1. **Event Generation**: Client sends POST request to `/events/generate`
2. **Validation**: Event payload is validated for required fields
3. **Event Creation**: Service generates `eventId` and `timestamp`
4. **Publishing**: Event is published to Kafka topic `user-activity-events`
5. **Consumption**: Kafka consumer receives and processes the event
6. **Idempotency Check**: Consumer checks if eventId was already processed
7. **Storage**: Event is stored in in-memory data structure (if not duplicate)
8. **Retrieval**: Client can query processed events via `/events/processed`

## ğŸ“¦ Prerequisites

- **Docker**: Version 20.10 or higher
- **Docker Compose**: Version 2.0 or higher
- **Node.js**: Version 18 or higher (for local development)

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone <repository-url>
cd kafka-microservice
```

### 2. Start All Services

```bash
docker-compose up --build
```

This command will:
- Start Zookeeper
- Start Kafka broker
- Build and start the application service
- Wait for all health checks to pass

### 3. Verify Services are Running

```bash
# Check service health
curl http://localhost:3000/health

# Expected response:
{
  "status": "ok",
  "timestamp": "2026-02-10T...",
  "service": "kafka-event-microservice",
  "kafka": {
    "producer": "connected"
  },
  "eventStore": {
    "processedEvents": 0
  }
}
```

### 4. Generate an Event

```bash
curl -X POST http://localhost:3000/events/generate \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "user-123",
    "eventType": "LOGIN",
    "payload": {
      "ip": "192.168.1.1",
      "userAgent": "Mozilla/5.0"
    }
  }'

# Expected response:
{
  "message": "Event published successfully",
  "eventId": "a1b2c3d4-...",
  "timestamp": "2026-02-10T..."
}
```

### 5. Query Processed Events

```bash
curl http://localhost:3000/events/processed

# Expected response:
{
  "count": 1,
  "events": [
    {
      "eventId": "a1b2c3d4-...",
      "userId": "user-123",
      "eventType": "LOGIN",
      "timestamp": "2026-02-10T...",
      "payload": {
        "ip": "192.168.1.1",
        "userAgent": "Mozilla/5.0"
      }
    }
  ]
}
```

## ğŸ“š API Documentation

### Base URL
```
http://localhost:3000
```

### Endpoints

#### 1. Generate Event

**Endpoint**: `POST /events/generate`

**Description**: Generates and publishes a user activity event to Kafka.

**Request Body**:
```json
{
  "userId": "string (required)",
  "eventType": "LOGIN | LOGOUT | PRODUCT_VIEW (required)",
  "payload": "object (optional)"
}
```

**Response** (201 Created):
```json
{
  "message": "Event published successfully",
  "eventId": "uuid-string",
  "timestamp": "ISO-8601-timestamp"
}
```

**Error Responses**:
- `400 Bad Request`: Invalid payload
- `500 Internal Server Error`: Kafka publishing failure
- `503 Service Unavailable`: Kafka not connected

**Example**:
```bash
curl -X POST http://localhost:3000/events/generate \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "user-456",
    "eventType": "PRODUCT_VIEW",
    "payload": {
      "productId": "prod-789",
      "category": "electronics"
    }
  }'
```

#### 2. Get Processed Events

**Endpoint**: `GET /events/processed`

**Description**: Retrieves all events that have been successfully consumed and processed.

**Response** (200 OK):
```json
{
  "count": 2,
  "events": [
    {
      "eventId": "uuid-1",
      "userId": "user-123",
      "eventType": "LOGIN",
      "timestamp": "ISO-8601-timestamp",
      "payload": {}
    },
    {
      "eventId": "uuid-2",
      "userId": "user-456",
      "eventType": "PRODUCT_VIEW",
      "timestamp": "ISO-8601-timestamp",
      "payload": {
        "productId": "prod-789"
      }
    }
  ]
}
```

**Example**:
```bash
curl http://localhost:3000/events/processed
```

#### 3. Health Check

**Endpoint**: `GET /health`

**Description**: Returns the health status of the service and its dependencies.

**Response** (200 OK):
```json
{
  "status": "ok",
  "timestamp": "ISO-8601-timestamp",
  "service": "kafka-event-microservice",
  "kafka": {
    "producer": "connected"
  },
  "eventStore": {
    "processedEvents": 5
  }
}
```

**Example**:
```bash
curl http://localhost:3000/health
```

## ğŸ§ª Testing

### Run All Tests

```bash
# Run all tests with coverage
npm test

# Or using Docker
docker-compose exec app-service npm test
```

### Run Unit Tests Only

```bash
npm run test:unit

# Or using Docker
docker-compose exec app-service npm run test:unit
```

### Run Integration Tests Only

```bash
npm run test:integration

# Or using Docker
docker-compose exec app-service npm run test:integration
```

### Test Coverage

The project maintains high test coverage:
- **Unit Tests**: Validator, EventStore, business logic
- **Integration Tests**: End-to-end API flows, Kafka integration

Expected output:
```
Test Suites: 3 passed, 3 total
Tests:       30+ passed, 30+ total
Coverage:    > 85%
```

## ğŸ“ Project Structure

```
kafka-microservice/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â””â”€â”€ eventController.js      # API endpoint handlers
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ eventStore.js           # In-memory event storage
â”‚   â”‚   â”œâ”€â”€ kafkaProducer.js        # Kafka producer service
â”‚   â”‚   â””â”€â”€ kafkaConsumer.js        # Kafka consumer service
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ logger.js               # Winston logger configuration
â”‚   â”‚   â””â”€â”€ validator.js            # Event validation utilities
â”‚   â”œâ”€â”€ app.js                       # Express app setup
â”‚   â”œâ”€â”€ routes.js                    # API route definitions
â”‚   â””â”€â”€ index.js                     # Application entry point
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ validator.test.js       # Validator unit tests
â”‚   â”‚   â””â”€â”€ eventStore.test.js      # EventStore unit tests
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ api.test.js              # API integration tests
â”œâ”€â”€ config/
â”‚   â””â”€â”€ index.js                     # Application configuration
â”œâ”€â”€ docker-compose.yml               # Docker orchestration
â”œâ”€â”€ Dockerfile                       # Application container definition
â”œâ”€â”€ package.json                     # Node.js dependencies
â”œâ”€â”€ .env.example                     # Environment variables template
â”œâ”€â”€ .gitignore                       # Git ignore rules
â”œâ”€â”€ README.md                        # This file
â””â”€â”€ ARCHITECTURE.md                  # Detailed architecture documentation
```

## âš™ï¸ Configuration

### Environment Variables

Copy `.env.example` to `.env` and customize as needed:

```bash
cp .env.example .env
```

**Available Variables**:

| Variable | Description | Default |
|----------|-------------|---------|
| `NODE_ENV` | Environment (development/production) | `development` |
| `PORT` | Application port | `3000` |
| `APP_NAME` | Application name | `kafka-microservice` |
| `KAFKA_BROKER` | Kafka broker address | `kafka:9092` |
| `KAFKA_CLIENT_ID` | Kafka client identifier | `event-microservice` |
| `KAFKA_TOPIC` | Kafka topic name | `user-activity-events` |
| `KAFKA_CONSUMER_GROUP` | Consumer group ID | `user-activity-consumer-group` |
| `KAFKA_CONNECTION_TIMEOUT` | Connection timeout (ms) | `30000` |
| `KAFKA_REQUEST_TIMEOUT` | Request timeout (ms) | `30000` |
| `KAFKA_RETRY_ATTEMPTS` | Number of retry attempts | `5` |
| `KAFKA_RETRY_DELAY` | Delay between retries (ms) | `300` |
| `LOG_LEVEL` | Logging level | `info` |

## ğŸ› ï¸ Development

### Local Development Setup

1. **Install Dependencies**:
```bash
npm install
```

2. **Start Kafka (Docker)**:
```bash
docker-compose up zookeeper kafka
```

3. **Run Application Locally**:
```bash
npm run dev
```

### Stopping Services

```bash
# Stop all services
docker-compose down

# Stop and remove volumes (cleans Kafka data)
docker-compose down -v
```

### Viewing Logs

```bash
# View all logs
docker-compose logs -f

# View specific service logs
docker-compose logs -f app-service
docker-compose logs -f kafka
```

### Accessing Kafka Container

```bash
# Access Kafka container
docker-compose exec kafka bash

# List topics
kafka-topics --list --bootstrap-server localhost:9092

# Consume messages from topic
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic user-activity-events --from-beginning
```

## ğŸ” Monitoring and Debugging

### Check Kafka Topics

```bash
docker-compose exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

### Monitor Kafka Messages

```bash
docker-compose exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic user-activity-events \
  --from-beginning \
  --property print.key=true
```

### View Application Logs

```bash
docker-compose logs -f app-service
```

## ğŸ¯ Key Implementation Details

### Idempotency

The consumer implements idempotency using a Set to track processed `eventId` values:

```javascript
// Only process if not already seen
if (this.processedEventIds.has(event.eventId)) {
  logger.info(`Duplicate event detected: ${event.eventId}. Skipping.`);
  return false;
}
```

### Error Handling

- **Producer**: Retries on transient failures, logs permanent failures
- **Consumer**: Gracefully handles malformed messages without crashing
- **API**: Returns appropriate HTTP status codes and error messages

### Graceful Shutdown

The application handles SIGTERM and SIGINT signals:

```javascript
process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));
```

## ğŸ“ License

MIT

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

